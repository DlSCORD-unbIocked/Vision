# Vision

## TODO List
- [ ] Create hand gesture detection
- [ ] Create functions that are triggered by gestures
- [ ] Bug fixes
- [ ] Train more gestures
- [ ] Documentation
- [ ] Create a GUI
- [ ] Multi-Language support
- [ ] Lip-Reading support
- [ ] Training for Lip-Reading support

## Use:

`pip install requirements.txt`

`python app.py` in hand_test_1/recognition for the hand gesture recognition

`python 3.10`

## Gestures

**Openâœ‹: 0, 
CloseğŸ‘Š: 1, Pointerâ˜ï¸: 2, OkğŸ‘Œ: 3, Thumbs upğŸ‘: 4, CoyoteğŸ¤˜: 5**

## Description

This is a project that uses hand gestures to control the computer. The project uses a camera to detect hand gestures and then uses the gestures. The project is still in development and is not yet complete.

There are currently two methods of moving the mouse. The first method is with moving the thumb, and pinching with index finger will send a click, holding down will hold mouse. The second method is with moving the index finger, and clicking with a gesture.

## Training

You can train the model by running keypoint_classification.ipynb with jupyter or Google colab. in the hand_test_1/recognition folder. This will train the model and save it to the `model` folder. You can collect data by pressing k for manual snapshot or t for rapid.
