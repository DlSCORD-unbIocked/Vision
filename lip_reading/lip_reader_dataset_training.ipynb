{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!unzip drive/MyDrive/data/cropped.zip -d cropped"
   ],
   "metadata": {
    "id": "h0Xp9Wd1_McB"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uHGhWXjI7ASG",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7cca8e5b-9372-417f-ad99-2701cf7d72e5"
   },
   "source": [
    "!pip install tqdm==4.64.1\n",
    "!pip install dlib\n",
    "!pip install face_recognition\n",
    "!pip install -Uqq fastbook"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import os\n",
    "#import face_recognition\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "import shutil"
   ],
   "metadata": {
    "id": "q10e9op6B1Pe"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "cap = cv2.VideoCapture('drive/MyDrive/bee.mp4')\n",
    "(major_ver, minor_ver, subminor_ver) = (cv2.__version__).split('.')\n",
    "\n",
    "if int(major_ver)  < 3 :\n",
    "  fps = cap.get(cv2.cv.CV_CAP_PROP_FPS)\n",
    "else :\n",
    "  fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "frame_count = int(cap. get(cv2. CAP_PROP_FRAME_COUNT))\n",
    "print(\"Frames: \" + str(frame_count))\n",
    "print(\"Frames per second: \" + str(fps))\n",
    "print(\"lenght: \" + str(frame_count/fps))\n",
    "cap.release()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j5OjbuqWBbYh",
    "outputId": "f5bb0b5e-3896-42c5-bbce-f2263510e276"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# split video into frames\n",
    "\n",
    "video = cv2.VideoCapture('bee.mp4')\n",
    "\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "num_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "!mkdir frames\n",
    "\n",
    "for i in tqdm(range(num_frames)):\n",
    "\n",
    "    ret, frame = video.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "    if not os.path.exists(f'frames/frame_{i}.jpg'):\n",
    "      cv2.imwrite(f'frames/frame_{i}.jpg', frame)\n",
    "\n",
    "video.release()\n"
   ],
   "metadata": {
    "id": "rrrIVlhr7zcd"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# then find landmarks and using face_detection\n",
    "# im going to split it into chunks 0-20000, 20000-40000, 40000-60000, 60000-80000, 80000-100000, 100000-120000, 120000-131664\n",
    "# hard coded\n",
    "\n",
    "!mkdir cropped\n",
    "\n",
    "def crop(points):\n",
    "  x_min = min(point[0] for point in points)\n",
    "  x_max = max(point[0] for point in points)\n",
    "  y_min = min(point[1] for point in points)\n",
    "  y_max = max(point[1] for point in points)\n",
    "  return x_min, y_min, x_max, y_max\n",
    "\n",
    "frame_count = 131664\n",
    "\n",
    "for i in tqdm(range(0, 20000)):\n",
    "  num = str(i+1)\n",
    "  for _ in range(len(str(frame_count))-len(num)):\n",
    "    num = '0'+ num\n",
    "  frame = cv2.imread(f\"frames/frame_{i}.jpg\")\n",
    "  face_landmarks_list = face_recognition.face_landmarks(frame)\n",
    "  if face_landmarks_list != []:\n",
    "    [x, y, w, h] = crop(face_landmarks_list[0]['top_lip'] + face_landmarks_list[0]['bottom_lip'])\n",
    "    frame = frame[y:h, x:w]\n",
    "  if not os.path.exists(f\"cropped/{num}.jpg\"):\n",
    "    cv2.imwrite(f\"cropped/{num}.jpg\", frame)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "KXejXpyf7aKS"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FYWSSMr7w7_0",
    "outputId": "95c33b10-4eaa-4a44-eae9-82593424e693"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "!zip -r cropped.zip cropped/\n",
    "!cp cropped.zip \"/content/drive/MyDrive/data/cropped.zip\""
   ],
   "metadata": {
    "id": "XCXJheQsyRwk"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# then align each frame a with phoneme\n",
    "align = json.load(open(\"drive/MyDrive/data/align.json\"))['words']\n",
    "aligned = []\n",
    "\n",
    "for _d in range(len(align)):\n",
    "  d = align[_d]\n",
    "  if d[\"case\"] == \"success\":\n",
    "    if _d > 0 and align[_d-1][\"case\"] == \"success\" and d[\"start\"] - align[_d-1][\"end\"] != 0:\n",
    "      aligned.append({\"duration\":d[\"start\"] - align[_d-1][\"end\"],\"phone\":\"none\",\"start\":align[_d-1][\"end\"],\"end\":d[\"start\"],\"case\":\"success\"})\n",
    "    phones = d[\"phones\"]\n",
    "    for p in range(len(phones)):\n",
    "      if p == 0:\n",
    "        phones[p][\"start\"] = d[\"start\"]\n",
    "        phones[p][\"end\"] = phones[p][\"start\"] + phones[p][\"duration\"]\n",
    "      else:\n",
    "        phones[p][\"start\"] = phones[p-1][\"end\"]\n",
    "        phones[p][\"end\"] = phones[p][\"start\"] + phones[p][\"duration\"]\n",
    "      phones[p][\"case\"] = \"success\"\n",
    "      phones[p][\"phone\"] = phones[p][\"phone\"].split(\"_\")[0]\n",
    "      phones[p][\"duration\"] = phones[p][\"end\"] - phones[p][\"start\"]\n",
    "      if phones[p][\"phone\"] == \"oov\":\n",
    "        phones[p][\"case\"] = \"failed\"\n",
    "        phones[p][\"phone\"] = \"none\"\n",
    "    for i in phones:\n",
    "      aligned.append(i)\n",
    "  elif align[_d][\"case\"] != \"success\" and align[_d-1][\"case\"] == \"success\" and _d != 0:\n",
    "    index = _d\n",
    "    while True:\n",
    "      index += 1\n",
    "      if align[index][\"case\"] == \"success\":\n",
    "        aligned.append({\"duration\":align[index][\"start\"] - align[_d-1][\"end\"],\"phone\":\"none\",\"start\":align[_d-1][\"end\"],\"end\":align[index][\"start\"],\"case\":\"failed\"})\n",
    "        break\n",
    "  elif align[_d][\"case\"] != \"success\" and _d == 0:\n",
    "    index = _d\n",
    "    while True:\n",
    "      index += 1\n",
    "      if align[index][\"case\"] == \"success\":\n",
    "        aligned.append({\"duration\":align[index][\"start\"],\"phone\":\"none\",\"start\":0,\"end\":align[index][\"start\"],\"case\":\"failed\"})\n",
    "        break\n",
    "\n",
    "pd.DataFrame(aligned)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2777
    },
    "id": "iA0pnind9ycx",
    "outputId": "af1476dc-4a6b-4241-a2cd-9a4f27ce4a5e"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "frame_phone = []\n",
    "\n",
    "for i in tqdm(range(frame_count)):\n",
    "  now = {}\n",
    "  num = str(i+1)\n",
    "  for _ in range(len(str(frame_count))-len(num)):\n",
    "    num = '0'+ num\n",
    "  num = f'cropped/cropped/{num}' + '.jpg'\n",
    "  time = (i+1)/fps\n",
    "  for a in aligned:\n",
    "    if a[\"start\"] <= time and a[\"end\"] > time:\n",
    "      now[\"image\"] = num\n",
    "      now[\"phone\"] = a[\"phone\"]\n",
    "      now[\"case\"] = a[\"case\"]\n",
    "  frame_phone.append(now)\n",
    "\n",
    "df = pd.DataFrame(frame_phone)\n",
    "df.to_csv('drive/MyDrive/data/data.csv')\n",
    "df"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 718
    },
    "id": "9Vth0qniA7LH",
    "outputId": "6ef5d2ae-cdf2-4ed1-e1d8-3566111af35d"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"drive/MyDrive/data/data.csv\")\n",
    "df.phone.value_counts()\n",
    "#df.case.value_counts()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "id": "F3qoj_NgO2U6",
    "outputId": "bd4f0d3e-4729-4fc8-9e64-284f38d0cdc5"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df[20:60]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "lJ04TCPVPH5I",
    "outputId": "6e4631d7-a6a0-48dd-9dfa-4f9150f3ad73"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "import fastbook\n",
    "from fastbook import *\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import math\n",
    "Image.open(('cropped/cropped/000001.jpg'))"
   ],
   "metadata": {
    "id": "SfOg-MERuLYe",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 61
    },
    "outputId": "bc4a8e17-a978-400a-b132-4ae43ceaaa96"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "root_dir = \"drive/MyDrive/data/train_phone\"\n",
    "\n",
    "for i, r in tqdm(df.iterrows()):\n",
    "    if pd.isna(r.image):\n",
    "      continue\n",
    "    if not os.path.exists(f\"{root_dir}/{r.phone}\"):\n",
    "        os.makedirs(f\"{root_dir}/{r.phone}\")\n",
    "    shutil.copy(f\"{r.image}\", f\"{root_dir}/{r.phone}/{r.image.split('/')[-1]}\")\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aLZM-wkdPLt8",
    "outputId": "d916672f-86dd-468d-d500-54cb0fb5dd15"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "fields = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock),\n",
    "    get_items=get_image_files,\n",
    "    get_y=parent_label,\n",
    "    splitter=RandomSplitter(valid_pct=0.2, seed=42), # GrandparentSplitter(valid_name='validation')\n",
    "    item_tfms=RandomResizedCrop(224, min_scale=1),\n",
    "    batch_tfms=aug_transforms()\n",
    ")"
   ],
   "metadata": {
    "id": "01ZvHxdXzrbO"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "dls = fields.dataloaders(\"drive/MyDrive/data/train_phone/\")"
   ],
   "metadata": {
    "id": "nPQrneyR7i1S"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "dls.vocab"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "----bl8s73Fq",
    "outputId": "7d0bcd78-e190-4430-d293-05dffdd0c819"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "dls.train.show_batch(max_n=8, nrows=2)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 464
    },
    "id": "RhP7XqT68Agf",
    "outputId": "7728a579-811d-4234-f06d-38866ded108e"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "learner = cnn_learner(dls, resnet34, metrics=[error_rate, accuracy])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y4ihOol28Fgc",
    "outputId": "a2bb6c3a-2c0e-4916-ef0c-5d2d360af925"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "learner.lr_find()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "YdATn8t68MK-",
    "outputId": "1f9dc037-ffca-4499-ec2e-a389daa0ef57"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "learner.fine_tune(epochs=6, freeze_epochs=1, base_lr=0.0021)"
   ],
   "metadata": {
    "id": "jJxYuwCG8XK-"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "interp = ClassificationInterpretation.from_learner(learner)\n",
    "interp.plot_confusion_matrix(figsize=(12,12), dpi=60)"
   ],
   "metadata": {
    "id": "FLzqp-gL8koH"
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
