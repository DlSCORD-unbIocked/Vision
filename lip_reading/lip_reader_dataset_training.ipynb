{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!unzip drive/MyDrive/data/cropped.zip -d cropped"
   ],
   "metadata": {
    "id": "h0Xp9Wd1_McB"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uHGhWXjI7ASG"
   },
   "source": [
    "!pip install tqdm==4.64.1\n",
    "!pip install dlib\n",
    "!pip install face_recognition"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import os\n",
    "#import face_recognition\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "import shutil"
   ],
   "metadata": {
    "id": "q10e9op6B1Pe"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "cap = cv2.VideoCapture('drive/MyDrive/bee.mp4')\n",
    "(major_ver, minor_ver, subminor_ver) = (cv2.__version__).split('.')\n",
    "\n",
    "if int(major_ver)  < 3 :\n",
    "  fps = cap.get(cv2.cv.CV_CAP_PROP_FPS)\n",
    "else :\n",
    "  fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "frame_count = int(cap. get(cv2. CAP_PROP_FRAME_COUNT))\n",
    "print(\"Frames: \" + str(frame_count))\n",
    "print(\"Frames per second: \" + str(fps))\n",
    "print(\"lenght: \" + str(frame_count/fps))\n",
    "cap.release()\n",
    ""
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j5OjbuqWBbYh",
    "outputId": "f5bb0b5e-3896-42c5-bbce-f2263510e276"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# split video into frames\n",
    "\n",
    "video = cv2.VideoCapture('bee.mp4')\n",
    "\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "num_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "!mkdir frames\n",
    "\n",
    "for i in tqdm(range(num_frames)):\n",
    "\n",
    "    ret, frame = video.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "    if not os.path.exists(f'frames/frame_{i}.jpg'):\n",
    "      cv2.imwrite(f'frames/frame_{i}.jpg', frame)\n",
    "\n",
    "video.release()\n"
   ],
   "metadata": {
    "id": "rrrIVlhr7zcd"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# then find landmarks and using face_detection\n",
    "# im going to split it into chunks 0-20000, 20000-40000, 40000-60000, 60000-80000, 80000-100000, 100000-120000, 120000-131664\n",
    "# hard coded\n",
    "\n",
    "!mkdir cropped\n",
    "\n",
    "def crop(points):\n",
    "  x_min = min(point[0] for point in points)\n",
    "  x_max = max(point[0] for point in points)\n",
    "  y_min = min(point[1] for point in points)\n",
    "  y_max = max(point[1] for point in points)\n",
    "  return x_min, y_min, x_max, y_max\n",
    "\n",
    "frame_count = 131664\n",
    "\n",
    "for i in tqdm(range(0, 20000)):\n",
    "  num = str(i+1)\n",
    "  for _ in range(len(str(frame_count))-len(num)):\n",
    "    num = '0'+ num\n",
    "  frame = cv2.imread(f\"frames/frame_{i}.jpg\")\n",
    "  face_landmarks_list = face_recognition.face_landmarks(frame)\n",
    "  if face_landmarks_list != []:\n",
    "    [x, y, w, h] = crop(face_landmarks_list[0]['top_lip'] + face_landmarks_list[0]['bottom_lip'])\n",
    "    frame = frame[y:h, x:w]\n",
    "  if not os.path.exists(f\"cropped/{num}.jpg\"):\n",
    "    cv2.imwrite(f\"cropped/{num}.jpg\", frame)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "KXejXpyf7aKS"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FYWSSMr7w7_0",
    "outputId": "95c33b10-4eaa-4a44-eae9-82593424e693"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "!zip -r cropped.zip cropped/\n",
    "!cp cropped.zip \"/content/drive/MyDrive/data/cropped.zip\""
   ],
   "metadata": {
    "id": "XCXJheQsyRwk"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# then align each frame a with phoneme\n",
    "align = json.load(open(\"drive/MyDrive/data/align.json\"))['words']\n",
    "aligned = []\n",
    "\n",
    "for _d in range(len(align)):\n",
    "  d = align[_d]\n",
    "  if d[\"case\"] == \"success\":\n",
    "    if _d > 0 and align[_d-1][\"case\"] == \"success\" and d[\"start\"] - align[_d-1][\"end\"] != 0:\n",
    "      aligned.append({\"duration\":d[\"start\"] - align[_d-1][\"end\"],\"phone\":\"none\",\"start\":align[_d-1][\"end\"],\"end\":d[\"start\"],\"case\":\"success\"})\n",
    "    phones = d[\"phones\"]\n",
    "    for p in range(len(phones)):\n",
    "      if p == 0:\n",
    "        phones[p][\"start\"] = d[\"start\"]\n",
    "        phones[p][\"end\"] = phones[p][\"start\"] + phones[p][\"duration\"]\n",
    "      else:\n",
    "        phones[p][\"start\"] = phones[p-1][\"end\"]\n",
    "        phones[p][\"end\"] = phones[p][\"start\"] + phones[p][\"duration\"]\n",
    "      phones[p][\"case\"] = \"success\"\n",
    "      phones[p][\"phone\"] = phones[p][\"phone\"].split(\"_\")[0]\n",
    "      phones[p][\"duration\"] = phones[p][\"end\"] - phones[p][\"start\"]\n",
    "      if phones[p][\"phone\"] == \"oov\":\n",
    "        phones[p][\"case\"] = \"failed\"\n",
    "        phones[p][\"phone\"] = \"none\"\n",
    "    for i in phones:\n",
    "      aligned.append(i)\n",
    "  elif align[_d][\"case\"] != \"success\" and align[_d-1][\"case\"] == \"success\" and _d != 0:\n",
    "    index = _d\n",
    "    while True:\n",
    "      index += 1\n",
    "      if align[index][\"case\"] == \"success\":\n",
    "        aligned.append({\"duration\":align[index][\"start\"] - align[_d-1][\"end\"],\"phone\":\"none\",\"start\":align[_d-1][\"end\"],\"end\":align[index][\"start\"],\"case\":\"failed\"})\n",
    "        break\n",
    "  elif align[_d][\"case\"] != \"success\" and _d == 0:\n",
    "    index = _d\n",
    "    while True:\n",
    "      index += 1\n",
    "      if align[index][\"case\"] == \"success\":\n",
    "        aligned.append({\"duration\":align[index][\"start\"],\"phone\":\"none\",\"start\":0,\"end\":align[index][\"start\"],\"case\":\"failed\"})\n",
    "        break\n",
    "\n",
    "pd.DataFrame(aligned)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2777
    },
    "id": "iA0pnind9ycx",
    "outputId": "af1476dc-4a6b-4241-a2cd-9a4f27ce4a5e"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "frame_phone = []\n",
    "\n",
    "for i in tqdm(range(frame_count)):\n",
    "  now = {}\n",
    "  num = str(i+1)\n",
    "  for _ in range(len(str(frame_count))-len(num)):\n",
    "    num = '0'+ num\n",
    "  num = f'cropped/cropped/{num}' + '.jpg'\n",
    "  time = (i+1)/fps\n",
    "  for a in aligned:\n",
    "    if a[\"start\"] <= time and a[\"end\"] > time:\n",
    "      now[\"image\"] = num\n",
    "      now[\"phone\"] = a[\"phone\"]\n",
    "      now[\"case\"] = a[\"case\"]\n",
    "  frame_phone.append(now)\n",
    "\n",
    "df = pd.DataFrame(frame_phone)\n",
    "df.to_csv('drive/MyDrive/data/data.csv')\n",
    "df"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "id": "9Vth0qniA7LH",
    "outputId": "6ef5d2ae-cdf2-4ed1-e1d8-3566111af35d"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"drive/MyDrive/data/data.csv\")\n",
    "df.phone.value_counts()\n",
    "#df.case.value_counts()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F3qoj_NgO2U6",
    "outputId": "406346a5-db8b-4856-8ccd-d8e044d13601"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df[20:60]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "lJ04TCPVPH5I",
    "outputId": "2d2706a4-6511-410d-b3be-358a30f0da74"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "\n",
    "Image.open(('cropped/cropped/000001.jpg'))\n",
    "\n",
    "root_dir = \"drive/MyDrive/data/train_phone\"\n",
    "for _, r in df.iterrows():\n",
    "    num = str(_+1)\n",
    "    for _ in range(len(str(frame_count))-len(num)):\n",
    "      num = '0'+ num\n",
    "    if not os.path.exists(f\"{root_dir}/{r.phone}\"):\n",
    "        os.makedirs(f\"{root_dir}/{r.phone}\")\n",
    "    shutil.copy(f\"cropped/cropped/{num}.jpg\", f\"{root_dir}/{r.phone}/{r.image}\")\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "aLZM-wkdPLt8",
    "outputId": "4124195e-c249-4bd6-d5cd-03b561c87565"
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
