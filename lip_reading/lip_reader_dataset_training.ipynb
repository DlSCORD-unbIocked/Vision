{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uHGhWXjI7ASG",
    "outputId": "7ab83848-91d5-4b59-b1f4-3213ca5ad4b8"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting tqdm==4.64.1\n",
      "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/78.5 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m78.5/78.5 kB\u001B[0m \u001B[31m3.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: tqdm\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.66.4\n",
      "    Uninstalling tqdm-4.66.4:\n",
      "      Successfully uninstalled tqdm-4.66.4\n",
      "Successfully installed tqdm-4.64.1\n",
      "Requirement already satisfied: dlib in /usr/local/lib/python3.10/dist-packages (19.24.4)\n",
      "Collecting face_recognition\n",
      "  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting face-recognition-models>=0.3.0 (from face_recognition)\n",
      "  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m100.1/100.1 MB\u001B[0m \u001B[31m8.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (8.1.7)\n",
      "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (19.24.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from face_recognition) (1.25.2)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from face_recognition) (9.4.0)\n",
      "Building wheels for collected packages: face-recognition-models\n",
      "  Building wheel for face-recognition-models (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566170 sha256=a222949230ef4d2ceb1ea43c982c4eaa8abb0e769e4f21e9929391716db9e699\n",
      "  Stored in directory: /root/.cache/pip/wheels/7a/eb/cf/e9eced74122b679557f597bb7c8e4c739cfcac526db1fd523d\n",
      "Successfully built face-recognition-models\n",
      "Installing collected packages: face-recognition-models, face_recognition\n",
      "Successfully installed face-recognition-models-0.3.0 face_recognition-1.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm==4.64.1\n",
    "!pip install dlib\n",
    "!pip install face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import os\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json"
   ],
   "metadata": {
    "id": "q10e9op6B1Pe"
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# split video into frames\n",
    "\n",
    "video = cv2.VideoCapture('bee.mp4')\n",
    "\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "num_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "!mkdir frames\n",
    "\n",
    "for i in tqdm(range(num_frames)):\n",
    "\n",
    "    ret, frame = video.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "    if not os.path.exists(f'frames/frame_{i}.jpg'):\n",
    "      cv2.imwrite(f'frames/frame_{i}.jpg', frame)\n",
    "\n",
    "video.release()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rrrIVlhr7zcd",
    "outputId": "35eb3b99-8219-415b-ed6f-3d270b769987"
   },
   "execution_count": 10,
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘frames’: File exists\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 131664/131664 [15:41<00:00, 139.78it/s]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# then find landmarks and using face_detection\n",
    "# im going to split it into chunks 0-20000, 20000-40000, 40000-60000, 60000-80000, 80000-100000, 100000-120000, 120000-131664\n",
    "# hard coded\n",
    "\n",
    "!mkdir cropped\n",
    "\n",
    "def crop(points):\n",
    "  x_min = min(point[0] for point in points)\n",
    "  x_max = max(point[0] for point in points)\n",
    "  y_min = min(point[1] for point in points)\n",
    "  y_max = max(point[1] for point in points)\n",
    "  return x_min, y_min, x_max, y_max\n",
    "\n",
    "frame_count = 131664\n",
    "\n",
    "for i in tqdm(range(0, 20000)):\n",
    "  num = str(i+1)\n",
    "  for _ in range(len(str(frame_count))-len(num)):\n",
    "    num = '0'+ num\n",
    "  frame = cv2.imread(f\"frames/frame_{i}.jpg\")\n",
    "  face_landmarks_list = face_recognition.face_landmarks(frame)\n",
    "  if face_landmarks_list != []:\n",
    "    [x, y, w, h] = crop(face_landmarks_list[0]['top_lip'] + face_landmarks_list[0]['bottom_lip'])\n",
    "    frame = frame[y:h, x:w]\n",
    "  cv2.imwrite(f\"cropped/{num}.jpg\", frame)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KXejXpyf7aKS",
    "outputId": "2ae8d4f7-8157-4d0f-f604-f113b47acbc2"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mkdir: cannot create directory ‘cropped’: File exists\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  5%|▌         | 1018/20000 [03:07<1:06:02,  4.79it/s]"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# then align each frame a with phoneme\n",
    "align = json.load(open(\"align.json\"))['words']\n",
    "aligned = []\n",
    "\n",
    "for _d in range(len(align)):\n",
    "  d = align[_d]\n",
    "  if d[\"case\"] == \"success\":\n",
    "    if _d > 0 and align[_d-1][\"case\"] == \"success\" and d[\"start\"] - align[_d-1][\"end\"] != 0:\n",
    "      aligned.append({\"duration\":d[\"start\"] - align[_d-1][\"end\"],\"phone\":\"none\",\"start\":align[_d-1][\"end\"],\"end\":d[\"start\"],\"case\":\"success\"})\n",
    "    phones = d[\"phones\"]\n",
    "    for p in range(len(phones)):\n",
    "      if p == 0:\n",
    "        phones[p][\"start\"] = d[\"start\"]\n",
    "        phones[p][\"end\"] = phones[p][\"start\"] + phones[p][\"duration\"]\n",
    "      else:\n",
    "        phones[p][\"start\"] = phones[p-1][\"end\"]\n",
    "        phones[p][\"end\"] = phones[p][\"start\"] + phones[p][\"duration\"]\n",
    "      phones[p][\"case\"] = \"success\"\n",
    "      phones[p][\"phone\"] = phones[p][\"phone\"].split(\"_\")[0] \n",
    "      phones[p][\"duration\"] = phones[p][\"end\"] - phones[p][\"start\"]\n",
    "      if phones[p][\"phone\"] == \"oov\":\n",
    "        phones[p][\"case\"] = \"failed\"\n",
    "        phones[p][\"phone\"] = \"none\"\n",
    "    for i in phones:\n",
    "      aligned.append(i)\n",
    "  elif align[_d][\"case\"] != \"success\" and align[_d-1][\"case\"] == \"success\" and _d != 0:\n",
    "    index = _d\n",
    "    while True:\n",
    "      index += 1\n",
    "      if align[index][\"case\"] == \"success\":\n",
    "        aligned.append({\"duration\":align[index][\"start\"] - align[_d-1][\"end\"],\"phone\":\"none\",\"start\":align[_d-1][\"end\"],\"end\":align[index][\"start\"],\"case\":\"failed\"})\n",
    "        break\n",
    "  elif align[_d][\"case\"] != \"success\" and _d == 0:      \n",
    "    index = _d\n",
    "    while True:\n",
    "      index += 1\n",
    "      if align[index][\"case\"] == \"success\":\n",
    "        aligned.append({\"duration\":align[index][\"start\"],\"phone\":\"none\",\"start\":0,\"end\":align[index][\"start\"],\"case\":\"failed\"})\n",
    "        break\n",
    "\n",
    "pd.DataFrame(aligned)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iA0pnind9ycx",
    "outputId": "cb6408cb-9f86-452e-f35e-c74f563b6463"
   },
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ]
  }
 ]
}
