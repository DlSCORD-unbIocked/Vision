{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHGhWXjI7ASG",
        "outputId": "7ab83848-91d5-4b59-b1f4-3213ca5ad4b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tqdm==4.64.1\n",
            "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/78.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tqdm\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.4\n",
            "    Uninstalling tqdm-4.66.4:\n",
            "      Successfully uninstalled tqdm-4.66.4\n",
            "Successfully installed tqdm-4.64.1\n",
            "Requirement already satisfied: dlib in /usr/local/lib/python3.10/dist-packages (19.24.4)\n",
            "Collecting face_recognition\n",
            "  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting face-recognition-models>=0.3.0 (from face_recognition)\n",
            "  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.1/100.1 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (8.1.7)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (19.24.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from face_recognition) (1.25.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from face_recognition) (9.4.0)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566170 sha256=a222949230ef4d2ceb1ea43c982c4eaa8abb0e769e4f21e9929391716db9e699\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/eb/cf/e9eced74122b679557f597bb7c8e4c739cfcac526db1fd523d\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face_recognition\n",
            "Successfully installed face-recognition-models-0.3.0 face_recognition-1.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tqdm==4.64.1\n",
        "!pip install dlib\n",
        "!pip install face_recognition"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import face_recognition\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "q10e9op6B1Pe"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split video into frames\n",
        "\n",
        "video = cv2.VideoCapture('bee.mp4')\n",
        "\n",
        "fps = video.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "num_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "!mkdir frames\n",
        "\n",
        "for i in tqdm(range(num_frames)):\n",
        "\n",
        "    ret, frame = video.read()\n",
        "\n",
        "    if not ret:\n",
        "        break\n",
        "    if not os.path.exists(f'frames/frame_{i}.jpg'):\n",
        "      cv2.imwrite(f'frames/frame_{i}.jpg', frame)\n",
        "\n",
        "video.release()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrrIVlhr7zcd",
        "outputId": "35eb3b99-8219-415b-ed6f-3d270b769987"
      },
      "execution_count": 10,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘frames’: File exists\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131664/131664 [15:41<00:00, 139.78it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# then find landmarks and using face_detection\n",
        "# im going to split it into chunks 0-20000, 20000-40000, 40000-60000, 60000-80000, 80000-100000, 100000-120000, 120000-131664\n",
        "# hard coded\n",
        "\n",
        "!mkdir cropped\n",
        "\n",
        "def crop(points):\n",
        "  x_min = min(point[0] for point in points)\n",
        "  x_max = max(point[0] for point in points)\n",
        "  y_min = min(point[1] for point in points)\n",
        "  y_max = max(point[1] for point in points)\n",
        "  return x_min, y_min, x_max, y_max\n",
        "\n",
        "frame_count = 131664\n",
        "\n",
        "for i in tqdm(range(0, 20000)):\n",
        "  num = str(i+1)\n",
        "  for _ in range(len(str(frame_count))-len(num)):\n",
        "    num = '0'+ num\n",
        "  frame = cv2.imread(f\"frames/frame_{i}.jpg\")\n",
        "  face_landmarks_list = face_recognition.face_landmarks(frame)\n",
        "  if face_landmarks_list != []:\n",
        "    [x, y, w, h] = crop(face_landmarks_list[0]['top_lip'] + face_landmarks_list[0]['bottom_lip'])\n",
        "    frame = frame[y:h, x:w]\n",
        "  cv2.imwrite(f\"cropped/{num}.jpg\", frame)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXejXpyf7aKS",
        "outputId": "2ae8d4f7-8157-4d0f-f604-f113b47acbc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘cropped’: File exists\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 1018/20000 [03:07<1:06:02,  4.79it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# then align each frame a with phoneme"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iA0pnind9ycx",
        "outputId": "cb6408cb-9f86-452e-f35e-c74f563b6463"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n"
          ]
        }
      ]
    }
  ]
}